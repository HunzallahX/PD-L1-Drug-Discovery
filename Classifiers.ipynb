{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8891eb-1aea-4426-ab9b-5bac77513e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,root_mean_squared_error\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import sklearn\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ffe57-14d2-4348-a831-3330821f543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFPGEN = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=1024)\n",
    "AFPGEN = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2048)\n",
    "RFPGEN = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048)\n",
    "TTPGEN = rdFingerprintGenerator.GetTopologicalTorsionGenerator(fpSize=2048)\n",
    "\n",
    "def calculate_descriptors(mol: Chem.Mol, missingVal: float | None = 0.0) -> dict:\n",
    "    \"\"\"Calculate the full list of descriptors for a molecule.\n",
    "    adapted from\n",
    "    https://github.com/jonswain/tabpfn-tdc/blob/main/submission.py#L12\n",
    "    \"\"\"\n",
    "    \n",
    "    res = []\n",
    "    for nm, fn in Descriptors._descList:\n",
    "        try:\n",
    "            if nm!=\"Ipc\": # this one creates crazy values so we exclude it\n",
    "                val = fn(mol)\n",
    "        except:\n",
    "            val = missingVal\n",
    "        res.append(val)\n",
    "    return res\n",
    "\n",
    "def mol_feat(mol,morgan=True,tt=True,ap=True,descs=True,rdfp=True):\n",
    "    \"\"\"\n",
    "    Extracts features by combining:\n",
    "    - Morgan Fingerprints\n",
    "    - RDKit Descriptors\n",
    "    - Topological Torsion Fingerprints\n",
    "    Returns a concatenated NumPy array of all features.\n",
    "    \"\"\"\n",
    "    assert mol is not None, \"Invalid molecule.\"\n",
    "    features = []\n",
    "\n",
    "    #combine the features:\n",
    "    if morgan:\n",
    "        morgan_fp = MFPGEN.GetFingerprintAsNumPy(mol)\n",
    "        features.append(morgan_fp)\n",
    "    if tt:\n",
    "        torsion_fp = TTPGEN.GetFingerprintAsNumPy(mol)\n",
    "        features.append(torsion_fp)\n",
    "    if ap:\n",
    "        ap_fp = AFPGEN.GetFingerprintAsNumPy(mol)\n",
    "        features.append(ap_fp)\n",
    "    if descs:\n",
    "        rdkit_desc = calculate_descriptors(mol)  \n",
    "        features.append(rdkit_desc)\n",
    "    if rdfp:\n",
    "        rdkit_fp = RFPGEN.GetFingerprintAsNumPy(mol)\n",
    "        features.append(rdkit_fp)\n",
    "\n",
    "    # Concatenate all features into a single vector\n",
    "    combined_features = np.hstack(features)\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "\n",
    "def build_classification_model(X,y,mode=\"RandomForest\",model_options={\"n_estimators\":10,\"max_depth\":3,\"random_state\":123}):\n",
    "    if mode == \"RandomForest\":\n",
    "        model = RandomForestClassifier(**model_options)\n",
    "    elif mode == \"XGBoost\":\n",
    "        model = XGBClassifier(**model_options)\n",
    "    elif mode == \"Ridge\":\n",
    "        model = RidgeClassifier(**model_options)\n",
    "    elif mode == \"SVM\":\n",
    "        model = SVC(**model_options)\n",
    "    else:\n",
    "        print(\"mode not supported\")\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "def data_splitter(X,y,mode=\"Random\",test_ratio=0.2,seed=123):\n",
    "    if mode == \"Random\":\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_ratio,random_state=seed)\n",
    "    else:\n",
    "        print(\"mode not supported\")    \n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "m = Chem.MolFromSmiles(\"c1ccccc1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c49bd95-1100-4eda-839d-0c7874ed30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chembl = pd.read_csv(\"data/PDL1-CHEMBL.csv\", sep=\";\")\n",
    "mols = []\n",
    "y = []\n",
    "\n",
    "threshold = 6.0  \n",
    "\n",
    "for i, row in df_chembl.iterrows():\n",
    "    smiles = row[\"Smiles\"]\n",
    "    try:\n",
    "        pchembl = float(row[\"pChEMBL Value\"])\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            y.append(1 if pchembl >= threshold else 0)\n",
    "            mols.append(mol)\n",
    "    except:\n",
    "        continue  \n",
    "        \n",
    "X_chembl_ecfp = [mol_feat(m, descs=False, morgan=True, rdfp=False, ap=False, tt=False) for m in mols]\n",
    "X_chembl_rdk = [mol_feat(m, descs=False, morgan=False, rdfp=True, ap=False, tt=False) for m in mols]\n",
    "X_chembl_descs = [mol_feat(m, descs=True, morgan=False, rdfp=False, ap=False, tt=False) for m in mols]\n",
    "y_chembl = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e081679-7565-4fbb-a3ea-26fb3d1b1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paper = pd.read_excel(\"data/pharmaceuticals-1710563-supplementary.xlsx\")\n",
    "smiles_paper = list(set(df_paper[df_paper[\"Unnamed: 2\"] == \"ACTIVE\"][\"Unnamed: 3\"]))\n",
    "smiles_paper_decoys = list(set(df_paper[df_paper[\"Unnamed: 2\"] == \"DECOY\"][\"Unnamed: 3\"]))\n",
    "\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in smiles_paper+smiles_paper_decoys]\n",
    "X_paper_ecfp = [mol_feat(m, descs=False, morgan=True, rdfp=False, ap=False, tt=False) for m in mols]\n",
    "X_paper_rdk = [mol_feat(m, descs=False, morgan=False, rdfp=True, ap=False, tt=False) for m in mols]\n",
    "X_paper_descs = [mol_feat(m, descs=True, morgan=False, rdfp=False, ap=False, tt=False) for m in mols]\n",
    "y_paper = [1]*len(smiles_paper)+[0]*len(smiles_paper_decoys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d14b8-1738-4828-97b5-ad5372304a22",
   "metadata": {},
   "source": [
    "# Function for optimization of hyperparamaeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87971f85-2306-40b8-aa0c-8b47882856a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "def xgb_objective(trial):\n",
    "    xgb_max_depth = trial.suggest_int(\"xgb_max_depth\", 2, 32, log=True)\n",
    "    xgb_n_estimators = trial.suggest_int(\"xgb_n_estimators\", 10, 1000, log=True)\n",
    "    xgb_eta = trial.suggest_float(\"xgb_eta\", 0, 1)\n",
    "    xgb_gamma = trial.suggest_float(\"xgb_gamma\", 0, 1)\n",
    "    model = build_classification_model(X_train, y_train, mode=\"XGBoost\",\n",
    "                               model_options={\"n_estimators\":xgb_n_estimators, \"max_depth\":xgb_max_depth, \"random_state\":102, \"eta\":xgb_eta, \"gamma\":xgb_gamma})\n",
    "\n",
    "    score = sklearn.model_selection.cross_val_score(model, X_train, y_train, n_jobs=-1, cv=5,scoring=make_scorer(matthews_corrcoef))\n",
    "    score_avg = score.mean()\n",
    "    return score_avg\n",
    "\n",
    "def rf_objective(trial):\n",
    "    rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n",
    "    rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 10, 1000, log=True)\n",
    "    model = build_classification_model(X_train, y_train, mode=\"RandomForest\",\n",
    "                               model_options={\"n_estimators\":rf_n_estimators, \"max_depth\":rf_max_depth, \"random_state\":102})\n",
    "    score = sklearn.model_selection.cross_val_score(model, X_train, y_train, n_jobs=-1, cv=5,scoring=make_scorer(matthews_corrcoef))\n",
    "    score_avg = score.mean()\n",
    "    return score_avg\n",
    "\n",
    "def ridge_objective(trial):\n",
    "    return 0\n",
    "\n",
    "def svm_objective(trial):\n",
    "    svm_gamma = trial.suggest_float(\"svm_gamma\", 0.001, 1000, log=True)\n",
    "    svm_C = trial.suggest_int(\"svm_C\", 1, 1000, log=True)\n",
    "    model = build_classification_model(X_train, y_train, mode=\"SVM\",\n",
    "                               model_options={\"kernel\":\"rbf\", \"gamma\":svm_gamma,\"C\":svm_C}) #svm doesnt have random state\n",
    "\n",
    "    score = sklearn.model_selection.cross_val_score(model, X_train, y_train, n_jobs=-1, cv=5,scoring=make_scorer(matthews_corrcoef))\n",
    "    score_avg = score.mean()\n",
    "    return score_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bd9847f-4b7b-4571-b40b-322239d07fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(best_trial,X_train,y_train,X_test,y_test,modeltype,feature):\n",
    "    params = study.best_trial.params\n",
    "    if modeltype==\"SVM\":\n",
    "        model = build_classification_model(X_train, y_train, mode=\"SVM\",\n",
    "                                       model_options={\"kernel\":\"rbf\", \"gamma\":params[\"svm_gamma\"],\"C\":params[\"svm_C\"]}) #svm doesnt have random state\n",
    "    elif modeltype==\"RandomForest\":\n",
    "        model = build_classification_model(X_train, y_train, mode=\"RandomForest\",\n",
    "                                       model_options={\"n_estimators\":params[\"rf_n_estimators\"], \"max_depth\":params[\"rf_max_depth\"], \"random_state\":102})\n",
    "    \n",
    "    elif modeltype==\"XGB\":\n",
    "        model = build_classification_model(X_train, y_train, mode=\"XGBoost\",\n",
    "                                   model_options={\"n_estimators\":params[\"xgb_n_estimators\"], \"max_depth\":params[\"xgb_max_depth\"], \"random_state\":102, \"eta\":params[\"xgb_eta\"], \"gamma\":params[\"xgb_gamma\"]})\n",
    "    elif modeltype==\"Ridge\":\n",
    "        model = build_classification_model(X_train, y_train, mode=\"Ridge\",model_options={})\n",
    "    print(f\"{modeltype} {feature} metrics:\")\n",
    "    score = sklearn.model_selection.cross_val_score(model, X_train, y_train, n_jobs=-1, cv=5,scoring=make_scorer(matthews_corrcoef))\n",
    "    print(\"CV MCC \",round(score.mean(),3))\n",
    "    \n",
    "    score = sklearn.model_selection.cross_val_score(model, X_train, y_train, n_jobs=-1, cv=5,scoring=make_scorer(balanced_accuracy_score))\n",
    "    print(\"CV,bAcc\",round(score.mean(),3))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"test MCC \",round(matthews_corrcoef(y_test,y_pred),3))\n",
    "    print(\"test bAcc\",round(balanced_accuracy_score(y_test,y_pred),3))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414fff1-64af-4b25-8010-59b5998e2fdc",
   "metadata": {},
   "source": [
    "# Task 1:\n",
    "Classification of chembl data\n",
    "AND evaluation on not only test set but also patent data.\n",
    "We reuse the best hyperparameters for task 2 and task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "547743a6-456c-4507-8a95-5826e29a5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = {\"ecfp\":X_chembl_ecfp,\"rdk\":X_chembl_rdk,\"descs\":X_chembl_descs}\n",
    "model2optimizer = {\"RandomForest\":rf_objective,\"XGB\":xgb_objective,\"SVM\":svm_objective,\"Ridge\":ridge_objective}\n",
    "y = y_chembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c190a-e33e-4ee5-967d-0256ecbacc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"ecfp\",\"rdk\",\"descs\"]:\n",
    "    X = X_features[feature]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(X, y,seed=123)\n",
    "    for modeltype in [\"Ridge\",\"RandomForest\",\"XGB\",\"SVM\"]:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(model2optimizer[modeltype], n_trials=200, n_jobs=20)\n",
    "        print(study.best_trial)\n",
    "        print_metrics(study.best_trial,X_train,y_train,X_test,y_test,modeltype,feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f5746-6976-4259-8b6a-a0757781ad35",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Classification of patent data\n",
    "AND evaluation on not only test set but also chembl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c889d20-ffa3-44bf-9471-8753b163d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = {\"ecfp\":X_paper_ecfp,\"rdk\":X_paper_rdk,\"descs\":X_paper_descs}\n",
    "y = y_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f9e86-0d07-4416-9381-7c2ae3a4c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"ecfp\",\"rdk\",\"descs\"]:\n",
    "    X = X_features[feature]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(X, y,seed=123)\n",
    "    for modeltype in [\"Ridge\",\"RandomForest\",\"XGB\",\"SVM\"]:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(model2optimizer[modeltype], n_trials=200, n_jobs=20)\n",
    "        print(study.best_trial)\n",
    "        print_metrics(study.best_trial,X_train,y_train,X_test,y_test,modeltype,feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc01df-db15-4c70-b49b-0086ad30e330",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Classification on both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f703d-e1dd-40e0-8617-3245bff44628",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = {\"ecfp\":X_paper_ecfp+X_chembl_ecfp,\"rdk\":X_paper_rdk+X_chembl_rdk,\"descs\":X_paper_descs+X_chembl_descs}\n",
    "y = y_chembl+y_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d465d-198b-4202-9f44-cb4b6b3f4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"ecfp\",\"rdk\",\"descs\"]:\n",
    "    X = X_features[feature]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(X, y,seed=123)\n",
    "    for modeltype in [\"Ridge\",\"RandomForest\",\"XGB\",\"SVM\"]:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(model2optimizer[modeltype], n_trials=200, n_jobs=20)\n",
    "        print(study.best_trial)\n",
    "        print_metrics(study.best_trial,X_train,y_train,X_test,y_test,modeltype,feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
